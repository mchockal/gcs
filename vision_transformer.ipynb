{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94738ea7",
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1658442703853,
     "user": {
      "displayName": "Meena Chockalingam",
      "userId": "09228565184695634950"
     },
     "user_tz": 300
    },
    "id": "94738ea7"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import dataset\n",
    "from models import nvidia\n",
    "from models import transformer\n",
    "\n",
    "# Tqdm progress bar\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "LEARNING_RATE = 1e-6\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY_REGULARIZATION_TERM = 1e-8  # aiming for overfitting\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "\n",
    "# Citation:\n",
    "# - AverageMeter taken verbatim from the Assignment 2 training code.\n",
    "# - Remainder of code in this file based on Assignment 2 training code.\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train(epoch, data_loader, model, optimizer, criterion, scaler=None):\n",
    "    iter_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "\n",
    "    # Get the progress bar for later modification\n",
    "    progress_bar = tqdm_notebook(data_loader, ascii=True)\n",
    "\n",
    "    for idx, (data, target) in enumerate(progress_bar):\n",
    "        start = time.time()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # Forward pass and computation of loss.\n",
    "        with torch.autocast(\"cuda\"): #Automatic Mixed precision\n",
    "            out = model(data).reshape(target.shape)\n",
    "          # RMSE loss\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "        \n",
    "        # Backwards pass to determine gradients and update model parameters.\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "        losses.update(loss, out.shape[0])\n",
    "\n",
    "        iter_time.update(time.time() - start)\n",
    "        # if idx % 5 == 0:\n",
    "        #     print(('Epoch: [{0}][{1}/{2}]\\t'\n",
    "        #            'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t'\n",
    "        #            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "        #           .format(epoch, idx, len(data_loader), iter_time=iter_time, loss=losses)))\n",
    "\n",
    "        progress_bar.set_description_str(f\"Epoch {epoch}, Batch: {idx+1}, Loss: {loss.item():.4f}\")\n",
    "            # \"Batch: %d, Loss: %.4f\" % ((idx + 1), loss.item()))\n",
    "        \n",
    "    return losses.avg\n",
    "\n",
    "def validate(epoch, validation_loader, model, criterion):\n",
    "    iter_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # Get the progress bar for later modification\n",
    "    progress_bar = tqdm_notebook(validation_loader, ascii=True)\n",
    "\n",
    "    for idx, (data, target) in enumerate(progress_bar):\n",
    "        start = time.time()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        out = None\n",
    "        loss = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            # RMSE loss\n",
    "            loss = torch.sqrt(criterion(out, target))\n",
    "\n",
    "        # loss.squeeze()\n",
    "        losses.update(loss, out.shape[0])\n",
    "\n",
    "        iter_time.update(time.time() - start)\n",
    "\n",
    "        # if idx % 10 == 0:\n",
    "        #     print(('Epoch: [{0}][{1}/{2}]\\t'\n",
    "        #            'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t')\n",
    "        #           .format(epoch, idx, len(validation_loader), iter_time=iter_time, loss=losses))\n",
    "\n",
    "        progress_bar.set_description_str(f\"Batch: {idx+1}, Loss: {loss.item():.4f}\")\n",
    "           \n",
    "        \n",
    "        # progress_bar.set_description_str(\n",
    "        #     \"Batch: %d, Loss: %.4f\" % ((idx + 1), loss.item()))\n",
    "\n",
    "    print(\"* Average Loss @1: {loss.avg:.4f}\".format(loss=losses))\n",
    "    return losses.avg\n",
    "\n",
    "def test(testing_loader, model, criterion):\n",
    "    iter_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # Get the progress bar for later modification\n",
    "    progress_bar = tqdm_notebook(testing_loader, ascii=True)\n",
    "\n",
    "    for idx, (data, target) in enumerate(progress_bar):\n",
    "        start = time.time()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        out = None\n",
    "        loss = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            # MSE loss\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "        losses.update(loss, out.shape[0])\n",
    "\n",
    "        iter_time.update(time.time() - start)\n",
    "\n",
    "        progress_bar.set_description_str(f\"Batch: {idx+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(\"* Average Loss @1: {loss.avg:.4f}\".format(loss=losses))\n",
    "#   Return RMSE loss\n",
    "    return losses.avg ** 0.5 \n",
    "\n",
    "# RSME Loss function. eps prevents [nan] in the backward pass\n",
    "def RSMELoss(yhat, y, eps=1e-6):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2) + eps)\n",
    "\n",
    "def plots(losses, lr=LEARNING_RATE, reg=WEIGHT_DECAY_REGULARIZATION_TERM, batch=BATCH_SIZE, momentum=MOMENTUM):\n",
    "    fig1, ax1 = plt.subplots(figsize=(8, 10))\n",
    "    ax1.plot(losses[0], label='Training Loss')\n",
    "    ax1.plot(losses[1], label='Validation Loss')\n",
    "    ax1.set_xlabel('#Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'L-Curves -> Train & Valid LR={lr} , Reg_Term={reg}, Batch={batch}')\n",
    "    ax1.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8db460",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "2eb5c69b9f15454f9fd65fc067d949d2",
      "9b42eb2891a84897b1a9217bb4cec11a",
      "07f91b25dcfe48108b6e66d5760ca49f",
      "f1dc29cb2632492db29ceb852da9c540",
      "9e3299822bfc4589854776ce8a7cea00",
      "183ee70600fc4887a26fcf6547540bff",
      "ce78fd69b1aa48b9a1957d2095d1e6a2",
      "471a52d4bc964e0f87db3d96d8f84a35",
      "e5f5a2f3ec0240e5aaaf3cc4f6002022",
      "3a471c46222c4e299819aa4a379bc140",
      "87467d13556342859b6c2edaaf35f097"
     ]
    },
    "id": "ff8db460",
    "outputId": "ec35e129-21c3-41f9-bab4-639b7b337f8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CS6601 - AI\\Assignments\\assignment_4\\venv\\lib\\site-packages\\ipykernel_launcher.py:52: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3cb96707134b999e2fea601f00f600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss this epoch: 0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CS6601 - AI\\Assignments\\assignment_4\\venv\\lib\\site-packages\\ipykernel_launcher.py:98: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ed61a5cc144505a71ac4f2d104e932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CS6601 - AI\\Assignments\\assignment_4\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average Loss @1: 0.1355\n",
      "Best performing model so far average validation loss: 0.1355 on epoch 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b14118febaa430db2c47acf70f65a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss this epoch: 0.0708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f341c5391363497299fb6ad7b86e5a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average Loss @1: 0.1509\n",
      "Best performing model so far average validation loss: 0.1355 on epoch 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352b735141d2494b90439e7b8806ae3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_TRANSFORMER = True\n",
    "\n",
    "def main():\n",
    "    # Normalizing images per the paper and resizing each image.\n",
    "    transformations = [\n",
    "        # Citation:\n",
    "        # https://pytorch.org/vision/stable/transforms.html#scriptable-transforms\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "    \n",
    "    if TRAIN_TRANSFORMER:\n",
    "        # The PyTorch vit_b_16 model requires input images to be square and have height and width divisible by 16.\n",
    "        transformations.append(transforms.Resize((128, 128)))\n",
    "    else:\n",
    "        # CNN images are resized to 66 x 200 to match the size used in the original Nvidia paper.\n",
    "        transformations.append(transforms.Resize((128, 128)))\n",
    "    \n",
    "    transform = transforms.Compose(transformations)\n",
    "\n",
    "    # Loading in images with normalization and resizing applied.\n",
    "    training_set, validation_set, test_set = dataset.load_nvidia_dataset(transform=transform, batch_size=BATCH_SIZE)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    model = None\n",
    "    \n",
    "    if TRAIN_TRANSFORMER:\n",
    "        # Loading in the vision transformer model.\n",
    "        model = transformer.VisionTransformer(image_size=128, patch_size=8, num_layers=2, \\\n",
    "                                              num_heads=2, hidden_dim=32, mlp_dim=1024)\n",
    "    else:\n",
    "        # Loading in the NVIDIA DAVE-2 model.\n",
    "        model = nvidia.NvidiaDaveCNN()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    # Specify Mean Squared Error (MSE) or RSME as the criterion since this is a regression task.\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = RMSELoss()\n",
    "\n",
    "    # Using Stochastic Gradient Descent (SGD) as the optimizer.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                LEARNING_RATE,\n",
    "                                weight_decay=WEIGHT_DECAY_REGULARIZATION_TERM)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True) \n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    best = float('inf')\n",
    "    best_model = None\n",
    "    best_epoch = None\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # Training.\n",
    "        train_loss = train(epoch, training_set, model, optimizer, criterion, scaler=scaler)\n",
    "        temp = train_loss\n",
    "        temp.cpu()\n",
    "        temp = float(temp)\n",
    "        train_losses.append(temp)  # average losses\n",
    "        print(f\"Average training loss this epoch: {temp:.4f}\")\n",
    "\n",
    "        # Validation.\n",
    "        valid_loss = validate(epoch, test_set, model, criterion)\n",
    "        temp = valid_loss\n",
    "        temp.cpu()\n",
    "        temp = float(temp)\n",
    "        valid_losses.append(temp)\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        if valid_loss < best:\n",
    "            best = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch\n",
    "        print(f\"Best performing model so far average validation loss: {best:.4f} on epoch {best_epoch}\\n\")\n",
    "\n",
    "    print('Best Training Loss @1: {:.4f}'.format(best))\n",
    "\n",
    "    torch.save(best_model.state_dict(), './checkpoints/vision_transformer.pth')\n",
    "    \n",
    "    # Testing the best model.\n",
    "    test_loss = test(test_set, best_model, criterion)\n",
    "    \n",
    "    print('Test Loss @1: {:.4f}'.format(test_loss))\n",
    "\n",
    "    losses_to_plot = train_losses, valid_losses\n",
    "    plots(losses_to_plot, lr=LEARNING_RATE, reg=WEIGHT_DECAY_REGULARIZATION_TERM,\n",
    "          batch=BATCH_SIZE, momentum=MOMENTUM)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865e2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sigopt\n",
    "\n",
    "def evaluate(args):       \n",
    "        \n",
    "    # log source of hyperparameter suggestion\n",
    "    sigopt.log_metadata('optimizer', \"Adam\")\n",
    "    sigopt.log_model(\"Pre-Built Vision Transformer\")\n",
    "    sigopt.log_dataset(\"Udacity self-driving dataset \")\n",
    "    \n",
    "    sigopt.params.setdefault(\"learning_rate\", args['learning_rate'])\n",
    "    sigopt.params.setdefault(\"momentum\", args['momentum'])\n",
    "    sigopt.params.setdefault(\"reg\", args['reg'])\n",
    "    sigopt.params.setdefault(\"batch_size\", int(args['batch_size']))\n",
    "    \n",
    "    # Normalizing images per the paper and resizing each image to 66 x 200.\n",
    "    transform = transforms.Compose([\n",
    "        # Citation:\n",
    "        # https://pytorch.org/vision/stable/transforms.html#scriptable-transforms\n",
    "        transforms.Resize((64, 64)),\n",
    "    ])\n",
    "\n",
    "    # Loading in images with normalization and resizing applied.\n",
    "    training_set, validation_set, _ = dataset.load_nvidia_dataset(transform=transform, batch_size=int(sigopt.params.batch_size))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loading in the vision transformer model.\n",
    "    model = transformer.VisionTransformer(image_size=64, patch_size=8, num_layers=2, \\\n",
    "                                          num_heads=2, hidden_dim=32, mlp_dim=1024)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "    # Specify Mean Squared Error (MSE) as criterion since this is a regression task. (We ultimately take sqrt and convert it to RMSE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Using Stochastic Gradient Descent (SGD) as the optimizer.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), sigopt.params.learning_rate,\n",
    "                                weight_decay=sigopt.params.reg)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, verbose=True) \n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    best = float('inf')\n",
    "    best_model = None\n",
    "    best_epoch = None\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # Training.\n",
    "        train_loss = train(epoch, training_set, model, optimizer, criterion, scaler=scaler)\n",
    "        temp = train_loss\n",
    "        temp.cpu()\n",
    "        temp = float(temp)\n",
    "        train_losses.append(temp)  # average losses\n",
    "        print(f\"Average training loss this epoch: {temp:.4f}\")\n",
    "\n",
    "        # Validation.\n",
    "        valid_loss = validate(epoch, validation_set, model, criterion)  # JTS - changed from test to validation\n",
    "        temp = valid_loss\n",
    "        temp.cpu()\n",
    "        temp = float(temp)\n",
    "        valid_losses.append(temp)\n",
    "\n",
    "        # scheduler.step(train_loss)  # JTS - this may or may not interfere with sigopt\n",
    "\n",
    "        if valid_loss < best:\n",
    "            best = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch\n",
    "        print(f\"Best performing model so far average validation loss: {best:.4f} on epoch {best_epoch}\\n\")\n",
    "\n",
    "    print('Best Training Loss @1: {:.4f}'.format(best))\n",
    "\n",
    "    torch.save(best_model.state_dict(), './checkpoints/nvidia_dave2.pth')\n",
    "    sigopt.log_metric(name='MSE', value=best)\n",
    "    return best.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SIGOPT_API_TOKEN\"] = \"XWBIVDWCVQXALUZQFDHNGOELLLKDJBMOJALEPCNQXQGBNIGC\"\n",
    "os.environ['SIGOPT_PROJECT'] = 'prebuilt_vit'\n",
    "%reload_ext sigopt\n",
    "args = {\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.005,\n",
    "    'momentum': 0.9,\n",
    "    'reg': 0.0005\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904eacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%experiment\n",
    "{\n",
    "    'name': 'Pre-Built Vision Transformer Optimization',\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'MSE',\n",
    "            'strategy': 'optimize',\n",
    "            'objective': 'minimize',\n",
    "        }\n",
    "    ],\n",
    "    'parameters': [\n",
    "        {\n",
    "            'name': 'reg',\n",
    "            'type': 'double',\n",
    "            'bounds': {'min': 0.0001, 'max': 0.5},\n",
    "            'transformation': 'log'\n",
    "        },\n",
    "        {\n",
    "            'name': 'learning_rate',\n",
    "            'type': 'double',\n",
    "            'bounds': {'min': 0.0001, 'max': 0.9},\n",
    "            'transformation': 'log'\n",
    "        },\n",
    "        {\n",
    "            'name': 'batch_size',\n",
    "            'type': 'categorical',\n",
    "            'categorical_values': ['32', '64']\n",
    "        }\n",
    "    ],\n",
    "    'budget': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc250430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%optimize gcp_nvidia_cnn_optimization_run_4\n",
    "evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87561fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "vision_transformer.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07f91b25dcfe48108b6e66d5760ca49f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471a52d4bc964e0f87db3d96d8f84a35",
      "max": 286,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5f5a2f3ec0240e5aaaf3cc4f6002022",
      "value": 0
     }
    },
    "183ee70600fc4887a26fcf6547540bff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb5c69b9f15454f9fd65fc067d949d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b42eb2891a84897b1a9217bb4cec11a",
       "IPY_MODEL_07f91b25dcfe48108b6e66d5760ca49f",
       "IPY_MODEL_f1dc29cb2632492db29ceb852da9c540"
      ],
      "layout": "IPY_MODEL_9e3299822bfc4589854776ce8a7cea00"
     }
    },
    "3a471c46222c4e299819aa4a379bc140": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "471a52d4bc964e0f87db3d96d8f84a35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87467d13556342859b6c2edaaf35f097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b42eb2891a84897b1a9217bb4cec11a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_183ee70600fc4887a26fcf6547540bff",
      "placeholder": "​",
      "style": "IPY_MODEL_ce78fd69b1aa48b9a1957d2095d1e6a2",
      "value": "  0%"
     }
    },
    "9e3299822bfc4589854776ce8a7cea00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce78fd69b1aa48b9a1957d2095d1e6a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5f5a2f3ec0240e5aaaf3cc4f6002022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1dc29cb2632492db29ceb852da9c540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a471c46222c4e299819aa4a379bc140",
      "placeholder": "​",
      "style": "IPY_MODEL_87467d13556342859b6c2edaaf35f097",
      "value": " 0/286 [00:00&lt;?, ?it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
